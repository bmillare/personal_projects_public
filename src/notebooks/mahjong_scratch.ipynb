{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce924a1-b9b9-4e4e-a5fe-03e0b58627fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4f600-0b6d-46e4-9faa-20b6a081492f",
   "metadata": {},
   "source": [
    "# Easy Mahjong scratch work\n",
    "- only balls and sticks\n",
    "- only numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7686ece7-557c-49bc-bd8e-522b06203cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1b',\n",
       " '2b',\n",
       " '3b',\n",
       " '4b',\n",
       " '5b',\n",
       " '6b',\n",
       " '7b',\n",
       " '8b',\n",
       " '9b',\n",
       " '1s',\n",
       " '2s',\n",
       " '3s',\n",
       " '4s',\n",
       " '5s',\n",
       " '6s',\n",
       " '7s',\n",
       " '8s',\n",
       " '9s']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_list = [f\"{n}{t}\" for t in [\"b\",\"s\"] for n in range(1,10)]\n",
    "tiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a2af8d-3dfc-4c13-ace1-530a2ca64e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1b': 0,\n",
       " '2b': 1,\n",
       " '3b': 2,\n",
       " '4b': 3,\n",
       " '5b': 4,\n",
       " '6b': 5,\n",
       " '7b': 6,\n",
       " '8b': 7,\n",
       " '9b': 8,\n",
       " '1s': 9,\n",
       " '2s': 10,\n",
       " '3s': 11,\n",
       " '4s': 12,\n",
       " '5s': 13,\n",
       " '6s': 14,\n",
       " '7s': 15,\n",
       " '8s': 16,\n",
       " '9s': 17}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_to_id = {t: id for id, t in enumerate(tiles_list)}\n",
    "tiles_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a48914f-493c-455a-b891-a5a5128f068a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocabulary_size': 18, 'embedding_size': 17}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tiles_list)\n",
    "hp = {\n",
    "    'vocabulary_size': vocabulary_size,\n",
    "    'embedding_size': vocabulary_size-int(math.log10(vocabulary_size)), # unique 100% orthogonal directions, we don't get benefit of mostly orthogonal until 100+ dims\n",
    "}\n",
    "hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcdf7e52-9127-47d1-9277-8f8dd6fe6428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log10(torch.tensor(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "87cc9ef2-c700-45be-910d-2f85372ffd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinoyMahjongNet(nn.Module):\n",
    "    def __init__(self,hp):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size = hp['embedding_size']\n",
    "        self.vocabulary_size = vocabulary_size = hp['vocabulary_size']\n",
    "        self.embeddings = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.tokenization = nn.Linear(embedding_size,vocabulary_size,bias=False)\n",
    "        # consider adding dropout later, but want simple 2 hidden layer network\n",
    "        self.linear = nn.Sequential(\n",
    "            # input:\n",
    "            # - hand embedding (embedding_size)\n",
    "            # - discard tile embedding (embedding_size)\n",
    "            nn.Linear(embedding_size*2, embedding_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size*2,embedding_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size*2,embedding_size*2),\n",
    "            nn.ReLU(),\n",
    "            # output:\n",
    "            # - logits all tiles discard (embedding_size)\n",
    "            # - logits draw, pickup (2)\n",
    "            nn.Linear(embedding_size*2,embedding_size+2), # not a typo\n",
    "        )\n",
    "\n",
    "    def forward(self,hand_ids,top_discard_id):\n",
    "        assert hand_ids.dim() == 2\n",
    "        # assume embedding dim is high enough (and orthogonal enough) so that adding embeddings together can represent a hand\n",
    "        hand_e = self.embeddings(hand_ids).sum(dim=1)\n",
    "        # I'm doing adding since there isn't anything unique about position in the hand\n",
    "        x = torch.cat([hand_e,self.embeddings(top_discard_id)],dim=-1)\n",
    "        out = self.linear(x)\n",
    "        discard_e, draw_pickup_logits = torch.split(out,[self.embedding_size,2],dim=-1)\n",
    "        return self.tokenization(discard_e), draw_pickup_logits\n",
    "\n",
    "# challenge:\n",
    "# - we need to get probability via softmax\n",
    "#   - softmax will be across logits for LEGAL moves/actions only (requires filtering of LEGAL logits (for LEGAL actions) somewhere/somehow)\n",
    "#   - then we extract the probability for the action we ACTUALLY took (need to record this and pass through to here)\n",
    "# - is it possible to do this with pure torch/tensors of regular action sequence lengths across all batches? (ie not varying action sequences for different batches?)\n",
    "# - also need advantage computation\n",
    "\n",
    "# simplify re-think\n",
    "# - just have player_agent store log_probs for it's actions so we don't need to figure this out later\n",
    "def grpo_loss(per_player_reward, per_player_log_probs):\n",
    "    # because of game symmetry, each win is always 3, and each loss is -1, no need to normalize, as long as net reward is always 0\n",
    "    loss = -per_player_reward['n']*torch.hstack(per_player_log_probs['n']).sum()\n",
    "    for player in ['e','s','w']:\n",
    "        log_probs = per_player_log_probs[player]\n",
    "        if log_probs:\n",
    "            loss -= per_player_reward[player]*torch.hstack(log_probs).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "741eda89-b2aa-487a-995d-decffff54fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1161,  0.0445, -0.0216,  0.1236, -0.0127,  0.0729,  0.0948, -0.1137],\n",
       "         [ 0.1101,  0.0358,  0.0086,  0.1218, -0.0154,  0.0873,  0.0914, -0.0699]],\n",
       "        grad_fn=<MmBackward0>),\n",
       " tensor([[ 0.2390, -0.0518],\n",
       "         [ 0.2859, -0.0469]], grad_fn=<SplitWithSizesBackward0>))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "vocabulary_size = 8\n",
    "embedding_size = 4\n",
    "hand_size = 5\n",
    "batch_size = 2\n",
    "hp = {\n",
    "    'vocabulary_size': vocabulary_size,\n",
    "    'embedding_size': embedding_size,\n",
    "    'batch_size': batch_size,\n",
    "}\n",
    "net = PinoyMahjongNet(hp)\n",
    "\n",
    "hand = torch.randint(vocabulary_size,(batch_size, hand_size))\n",
    "top_discard = torch.randint(vocabulary_size,(batch_size,))\n",
    "hand, top_discard\n",
    "discard_tile, draw_pickup = net(hand,top_discard)\n",
    "discard_tile, draw_pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c3c5d90e-266a-4cb6-9f31-807b9cdabd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "directions = ['n','e','s','w']\n",
    "next_direction = {'n': 'e', 'e': 's', 's': 'w', 'w': 'n'}\n",
    "def random_init(tiles):\n",
    "    deck = tiles[:]*4\n",
    "    shuffle(deck)\n",
    "    # need a per player display (showing chow tiles), having upper case directions represent that\n",
    "    return {'deck': deck, 'discard': [], 'n': [], 'e': [], 's': [], 'w': [], 'N': [], 'E': [], 'S': [], 'W': []}\n",
    "\n",
    "def deal(state):\n",
    "    deck = state['deck']\n",
    "    for player in directions:\n",
    "        for i in range(4):\n",
    "            state[player].append(deck.pop())\n",
    "    return state\n",
    "\n",
    "def first_draw(state):\n",
    "    deck = state['deck']\n",
    "    state['n'].append(deck.pop())\n",
    "    state['turn'] = 'n'\n",
    "    return state\n",
    "\n",
    "def parse_tile(tile):\n",
    "    num_s, suit = tile\n",
    "    num = int(num_s)\n",
    "    return num, suit\n",
    "\n",
    "# mahjong is just chow + eyes\n",
    "def is_hand_mahjong(hand):\n",
    "    # check pair\n",
    "    counts = {}\n",
    "    for tile in hand:\n",
    "        counts[tile] = counts.get(tile,0)+1\n",
    "    paired_tiles = set()\n",
    "    for tile, count in counts.items():\n",
    "        if count >= 2:\n",
    "            paired_tiles.add(tile)\n",
    "    if not paired_tiles:\n",
    "        return False\n",
    "    for paired_tile in paired_tiles:\n",
    "        size = 2\n",
    "        tmp_hand = []\n",
    "        for tile in hand:\n",
    "            if size and paired_tile == tile:\n",
    "                size -= 1\n",
    "                continue\n",
    "            tmp_hand.append(tile)\n",
    "        piles = {'b': [], 's': [], 'c': []}\n",
    "        for tile in tmp_hand:\n",
    "            num, suit = parse_tile(tile)\n",
    "            piles[suit].append(num)\n",
    "        for suit, pile in piles.items():\n",
    "            if len(pile) < 3:\n",
    "                continue\n",
    "            pile.sort()\n",
    "            a, b, c = pile\n",
    "            if a+2 == b+1 == c:\n",
    "                return True\n",
    "    return False\n",
    "    \n",
    "def smallest_chow(hand, pickup):\n",
    "    if len(hand) < 2:\n",
    "        return None\n",
    "    matching_suit = []\n",
    "    d_num, d_suit = parse_tile(pickup)\n",
    "    for tile in hand:\n",
    "        num, suit = parse_tile(tile)\n",
    "        if suit == d_suit:\n",
    "            matching_suit.append(num)\n",
    "    matching_suit.sort()\n",
    "    for i in range(len(matching_suit)-1):\n",
    "        t1 = matching_suit[i]\n",
    "        t2 = matching_suit[i+1]\n",
    "        if d_num+2 == t1+1 == t2: # pickup starts chow\n",
    "            return [str(n)+d_suit for n in [d_num, t1, t2]]\n",
    "        if t1+2 == t2+1 == d_num: # pickup ends chow\n",
    "            return [str(n)+d_suit for n in [t1, t2, d_num]]\n",
    "    return None\n",
    "\n",
    "# either a draw or a pickup\n",
    "# what do we do if we run out of tiles? maybe handle this as part of orchestrator\n",
    "def action1(state,choice):\n",
    "    turn = state['turn']\n",
    "    hand = state[turn]\n",
    "    display = state[turn.upper()]\n",
    "    if not state['discard'] or choice == 'draw':\n",
    "        hand.append(state['deck'].pop())\n",
    "    else:\n",
    "        top_discard = state['discard'][-1]\n",
    "        if is_hand_mahjong(hand+state['discard'][-1:]+display):\n",
    "            hand.append(state['discard'].pop())\n",
    "            return state\n",
    "        s_chow = smallest_chow(hand,top_discard)\n",
    "        if s_chow:\n",
    "            state[turn.upper()] += s_chow\n",
    "            s_chow.remove(top_discard)\n",
    "            for tile in s_chow:\n",
    "                hand.remove(tile)\n",
    "            state['discard'].pop()\n",
    "        else:\n",
    "            assert False\n",
    "    return state\n",
    "\n",
    "# discard from hand\n",
    "def action2(state,choice):\n",
    "    turn = state['turn']\n",
    "    assert choice in state[turn]\n",
    "    state[turn].remove(choice)\n",
    "    state['discard'].append(choice)\n",
    "    # for easy mode, we can determine next turn already, but in advanced, we have between turn actions\n",
    "    state['turn'] = next_direction[turn]\n",
    "    return state\n",
    "\n",
    "# really, there should be an action 3: which chow/(pong for later) to show, cause sometimes you have a choice to pick what goes out of play\n",
    "# - to keep it simple for easy mode, we should have it default to smaller chow\n",
    "# - eg. 1,2, [3], 4,5  -> can have 1,2,3 or 3,4,5\n",
    "\n",
    "\n",
    "# player must draw\n",
    "def force_action1(state):\n",
    "    turn = state['turn']\n",
    "    hand = state[turn]\n",
    "    display = state[turn.upper()]\n",
    "    deck = state['deck']\n",
    "    assert len(hand)+len(display) == 4\n",
    "    hand.append(deck.pop())\n",
    "    return state\n",
    "    \n",
    "def find_winner(state):\n",
    "    for player in directions:\n",
    "        hand = state[player]\n",
    "        if is_hand_mahjong(hand):\n",
    "            return player, hand\n",
    "    return False\n",
    "\n",
    "# during action1, is it legal to pickup?\n",
    "# pickup can be from chow, or winning\n",
    "def can_pickup(state):\n",
    "    turn = state['turn']\n",
    "    hand = state[turn]\n",
    "    display = state[turn.upper()]\n",
    "    assert len(hand)+len(display) == 4\n",
    "    top_discard_tile = state['discard'][-1]\n",
    "    if is_hand_mahjong(hand+display+[top_discard_tile]):\n",
    "        return True\n",
    "    # is chow\n",
    "    d_num, d_suit = parse_tile(top_discard_tile)\n",
    "    matching_tiles = []\n",
    "    for tile in hand:\n",
    "        num, suit = parse_tile(tile)\n",
    "        if suit == d_suit:\n",
    "            matching_tiles.append(num)\n",
    "    unique_matching_tiles = list(set(matching_tiles))\n",
    "    unique_matching_tiles.sort()\n",
    "    for i in range(len(unique_matching_tiles)-1):\n",
    "        t1 = unique_matching_tiles[i]\n",
    "        t2 = unique_matching_tiles[i+1]\n",
    "        if t1+1 != t2:\n",
    "            continue\n",
    "        if d_num+1 == t1 or d_num-1 == t2:\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "    \n",
    "\n",
    "# move game forward, declaring what's next step if any (is game done?)\n",
    "def narrator(state):\n",
    "    is_winner = find_winner(state)\n",
    "    turn = state['turn']\n",
    "    if is_winner:\n",
    "        return {'game_over': True, 'winning_player': is_winner[0], 'winning_hand': is_winner[1], 'message': f\"game over: winner {is_winner[0]}\", 'turn': turn}\n",
    "    if not state['deck']:\n",
    "        return {'game_over': True, 'winning_player': 'draw', 'message': \"game is draw, no tiles left\", 'turn': turn}\n",
    "    hand = state[turn]\n",
    "    display = state[turn.upper()]\n",
    "    if len(hand)+len(display) == 4:\n",
    "        if can_pickup(state):\n",
    "            return {'game_over': False, 'message': f\"awaiting player {turn} to draw or pickup\", 'turn': turn, 'await_action': 1}\n",
    "        else:\n",
    "            return {'game_over': False, 'message': f\"player {turn} must draw\", 'turn': turn, 'force_action': 1}\n",
    "    if len(hand)+len(display) == 5:\n",
    "        return {'game_over': False, 'message': f\"awaiting player {turn} to discard\", 'turn': turn, 'await_action': 2}\n",
    "\n",
    "import random\n",
    "class SimpleMahjongAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # given state (extract top_discard_tile, hand) -> draw or pickup aka chow\n",
    "    def a1(self,state):\n",
    "        # always pickup\n",
    "        return 'pickup'\n",
    "    def a2(self,state):\n",
    "        # discard random tile\n",
    "        turn = state['turn']\n",
    "        return random.choice(state[turn])\n",
    "\n",
    "class DumbMahjongAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # given state (extract top_discard_tile, hand) -> draw or pickup aka chow\n",
    "    def a1(self,state):\n",
    "        # always draw\n",
    "        return 'draw'\n",
    "    def a2(self,state):\n",
    "        # discard random tile\n",
    "        turn = state['turn']\n",
    "        return random.choice(state[turn])\n",
    "\n",
    "#    def forward(self,hand_ids,top_discard_id,mask=None):\n",
    "#        assert hand_ids.dim() == 2\n",
    "#        hand_e = self.embeddings(hand_ids).sum(dim=1) # assume embedding dim is high enough (and orthogonal enough) so that adding embeddings together can represent a hand\n",
    "#        # I'm doing adding since there isn't anything unique about position in the hand\n",
    "#        x = torch.cat([hand_e,self.embeddings(top_discard_id)],dim=-1)\n",
    "#        out = self.linear(x)\n",
    "#        discard_e, draw_pickup_logits = torch.split(out,[self.embedding_size,2],dim=-1)\n",
    "#        return self.tokenization(discard), draw_pickup\n",
    "\n",
    "# per game agent\n",
    "draw_pickup_choice = ['draw','pickup']\n",
    "class NetMahjongAgentInference:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    def a1(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        display = state[turn.upper()]\n",
    "        top_discard = state['discard'][-1]\n",
    "        hand_ids = [tiles_to_id[tile] for tile in hand+display]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        _discard_id_logits, draw_pickup_logits = self.model(torch.tensor([hand_ids]),torch.tensor([top_discard_id]))\n",
    "        # might be the case that can't use torch to do batching cause each trajectory will be different and have interleaved python cpu logic\n",
    "        # or maybe it is possible, even if different actions via different masking/gathering\n",
    "        dist = torch.distributions.Categorical(logits=draw_pickup_logits[0])\n",
    "        choice = dist.sample()\n",
    "        return draw_pickup_choice[choice]\n",
    "    def a2(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        display = state[turn.upper()]\n",
    "        top_discard = state['discard'][-1] if state['discard'] else hand[0] # don't know how to encode dummy value to represent empty yet, just picking first tile for now\n",
    "        hand_ids = [tiles_to_id[tile] for tile in hand]\n",
    "        all_ids = [tiles_to_id[tile] for tile in hand+display]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        discard_id_logits, _draw_pickup_logits = self.model(torch.tensor([all_ids]),torch.tensor([top_discard_id]))\n",
    "        unique_hand_ids = list(set(hand_ids))\n",
    "        unique_hand_ids.sort()\n",
    "        # sample only from your hand, not just any possible tile\n",
    "        legal_discard_id_logits = discard_id_logits.gather(dim=1,index=torch.tensor(unique_hand_ids).unsqueeze(0))\n",
    "        dist = torch.distributions.Categorical(logits=legal_discard_id_logits[0])\n",
    "        unique_index = dist.sample()\n",
    "        tile_id = unique_hand_ids[unique_index]\n",
    "        return tiles_list[tile_id]\n",
    "\n",
    "class NetMahjongAgentTrainingV1:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.per_player_logits_and_actions = {'n': [], 'e': [], 's': [], 'w': []}\n",
    "    def a1(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        top_discard = state['discard'][-1]\n",
    "        hand_ids = [tiles_to_id[tile] for tile in hand]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        _discard_id_logits, draw_pickup_logits = self.model(torch.tensor([hand_ids]),torch.tensor([top_discard_id]))\n",
    "        # might be the case that can't use torch to do batching cause each trajectory will be different and have interleaved python cpu logic\n",
    "        # or maybe it is possible, even if different actions via different masking/gathering\n",
    "        dist = torch.distributions.Categorical(logits=draw_pickup_logits[0])\n",
    "        choice = dist.sample()\n",
    "        self.per_player_logits_and_actions[turn].append((draw_pickup_logits[0,:],choice))\n",
    "        return draw_pickup_choice[choice]\n",
    "    def a2(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        top_discard = state['discard'][-1] if state['discard'] else hand[0] # don't know how to encode dummy value to represent empty yet, just picking first tile for now\n",
    "        hand_ids = [tiles_to_id[tile] for tile in hand]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        discard_id_logits, _draw_pickup_logits = self.model(torch.tensor([hand_ids]),torch.tensor([top_discard_id]))\n",
    "        unique_hand_ids = list(set(hand_ids))\n",
    "        unique_hand_ids.sort()\n",
    "        # sample only from your hand, not just any possible tile\n",
    "        legal_discard_id_logits = discard_id_logits.gather(dim=1,index=torch.tensor(unique_hand_ids).unsqueeze(0))\n",
    "        dist = torch.distributions.Categorical(logits=legal_discard_id_logits[0])\n",
    "        unique_index = dist.sample()\n",
    "        tile_id = unique_hand_ids[unique_index]\n",
    "        return tiles_list[tile_id]\n",
    "# Thinking its easier to just accumulate the probabilities here and just have a training version of the agent and an inference version\n",
    "class NetMahjongAgentTrainingV2:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.per_player_log_probs = {'n': [], 'e': [], 's': [], 'w': []}\n",
    "    def a1(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        display = state[turn.upper()]\n",
    "        top_discard = state['discard'][-1]\n",
    "        #hand_ids = [tiles_to_id[tile] for tile in hand]\n",
    "        all_ids = [tiles_to_id[tile] for tile in hand+display]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        _discard_id_logits, draw_pickup_logits = self.model(torch.tensor([all_ids]),torch.tensor([top_discard_id]))\n",
    "        # might be the case that can't use torch to do batching cause each trajectory will be different and have interleaved python cpu logic\n",
    "        # or maybe it is possible, even if different actions via different masking/gathering\n",
    "        dist = torch.distributions.Categorical(logits=draw_pickup_logits[0])\n",
    "        choice = dist.sample()\n",
    "        log_probs = F.log_softmax(draw_pickup_logits[0],dim=-1)\n",
    "        self.per_player_log_probs[turn].append(log_probs[choice])\n",
    "        return draw_pickup_choice[choice]\n",
    "    def a2(self,state):\n",
    "        turn = state['turn']\n",
    "        hand = state[turn]\n",
    "        display = state[turn.upper()]\n",
    "        top_discard = state['discard'][-1] if state['discard'] else hand[0] # don't know how to encode dummy value to represent empty yet, just picking first tile for now\n",
    "        hand_ids = [tiles_to_id[tile] for tile in hand]\n",
    "        all_ids = [tiles_to_id[tile] for tile in hand+display]\n",
    "        top_discard_id = tiles_to_id[top_discard]\n",
    "        discard_id_logits, _draw_pickup_logits = self.model(torch.tensor([all_ids]),torch.tensor([top_discard_id]))\n",
    "        unique_hand_ids = list(set(hand_ids))\n",
    "        unique_hand_ids.sort()\n",
    "        # sample only from your hand, not just any possible tile\n",
    "        legal_discard_id_logits = discard_id_logits.gather(dim=1,index=torch.tensor(unique_hand_ids).unsqueeze(0))\n",
    "        dist = torch.distributions.Categorical(logits=legal_discard_id_logits[0])\n",
    "        unique_index = dist.sample()\n",
    "        tile_id = unique_hand_ids[unique_index]\n",
    "        log_probs = F.log_softmax(legal_discard_id_logits,dim=-1)[0]\n",
    "        self.per_player_log_probs[turn].append(log_probs[unique_index])\n",
    "        return tiles_list[tile_id]\n",
    "\n",
    "# sets up game\n",
    "# checks with narrator\n",
    "# gets actions from agent\n",
    "def game_manager(player_agent,game_statistics=None,training=True):\n",
    "    #print('start')\n",
    "    s0 = first_draw(deal(random_init(tiles_list)))\n",
    "    # ensure we didn't just get a win without moving\n",
    "    while find_winner(s0):\n",
    "        s0 = first_draw(deal(random_init(tiles_list)))\n",
    "    state = s0\n",
    "    narration = narrator(state)\n",
    "    i = 0\n",
    "    per_player_reward = {'n': -1.0, 'e': -1.0, 's': -1.0, 'w': -1.0}\n",
    "    while not narration['game_over']:\n",
    "        turn = state['turn']\n",
    "        #print(i,\"'\"+narration['message']+\"'\",turn,state[turn],state['discard'][-1:])\n",
    "        i += 1\n",
    "        force_action = narration.get('force_action',False)\n",
    "        if force_action:\n",
    "            if force_action == 1:\n",
    "                force_action1(state)\n",
    "            narration = narrator(state)\n",
    "            continue\n",
    "        await_action = narration['await_action']\n",
    "        if await_action == 1:\n",
    "            choice = player_agent.a1(state)\n",
    "            action1(state,choice)\n",
    "        elif await_action == 2:\n",
    "            choice = player_agent.a2(state)\n",
    "            action2(state,choice)\n",
    "        else:\n",
    "            assert False\n",
    "        narration = narrator(state)\n",
    "    #print(i,narration,turn,state[turn])\n",
    "    if training:\n",
    "        winning_player = narration['winning_player']\n",
    "        if winning_player != 'draw':\n",
    "            per_player_reward[winning_player] = 3.0\n",
    "        else:\n",
    "            game_statistics['game_lengths_draws'].append(i)\n",
    "        game_statistics['game_lengths_all'].append(i)\n",
    "        return {'per_player_reward': per_player_reward, 'per_player_log_probs': player_agent.per_player_log_probs}\n",
    "\n",
    "def multi_agent_game_manager(player_agent,opponent_agent,game_statistics=None,training=True):\n",
    "    #print('start')\n",
    "    s0 = first_draw(deal(random_init(tiles_list)))\n",
    "    # ensure we didn't just get a win without moving\n",
    "    while find_winner(s0):\n",
    "        s0 = first_draw(deal(random_init(tiles_list)))\n",
    "    state = s0\n",
    "    narration = narrator(state)\n",
    "    i = 0\n",
    "    player_direction = random.choice(['n','e','s','w'])\n",
    "    player_to_agent = {'n': opponent_agent, 'e': opponent_agent, 's': opponent_agent, 'w': opponent_agent}\n",
    "    player_to_agent[player_direction] = player_agent\n",
    "    while not narration['game_over']:\n",
    "        turn = state['turn']\n",
    "        active_agent = player_to_agent[turn]\n",
    "        print(i,\"'\"+narration['message']+\"'\",turn,state[turn],state['discard'][-1:])\n",
    "        i += 1\n",
    "        force_action = narration.get('force_action',False)\n",
    "        if force_action:\n",
    "            if force_action == 1:\n",
    "                force_action1(state)\n",
    "            narration = narrator(state)\n",
    "            continue\n",
    "        await_action = narration['await_action']\n",
    "        if await_action == 1:\n",
    "            choice = active_agent.a1(state)\n",
    "            action1(state,choice)\n",
    "        elif await_action == 2:\n",
    "            choice = active_agent.a2(state)\n",
    "            action2(state,choice)\n",
    "        else:\n",
    "            assert False\n",
    "        narration = narrator(state)\n",
    "    print(i,player_direction, narration,turn,state[turn])\n",
    "    reward = -1.0\n",
    "    if training:\n",
    "        winning_player = narration['winning_player']\n",
    "        win = 0\n",
    "        if winning_player == 'draw':\n",
    "            reward = -0.5\n",
    "            game_statistics['game_lengths_draws'].append(i)\n",
    "        elif winning_player == player_direction:\n",
    "            reward = 3.0\n",
    "            win = 1\n",
    "        game_statistics['game_lengths_all'].append(i)\n",
    "        return {'win': win, 'reward': reward, 'log_probs': player_agent.per_player_log_probs[player_direction]}\n",
    "\n",
    "def simple_trainer(model,j=0):\n",
    "    game_statistics = {'game_lengths_all': [], 'game_lengths_draws': []}\n",
    "\n",
    "    loss = None\n",
    "    optimizer = Adam(model.parameters(),lr=0.1)\n",
    "    model.train()\n",
    "    total_loss = None\n",
    "    for i in range(100):\n",
    "        no_data = True\n",
    "        while no_data:\n",
    "            agent = NetMahjongAgentTrainingV2(model)\n",
    "            training_data = game_manager(agent,game_statistics)\n",
    "            if training_data is None: # if we want to exclude this game from training, game_manager should return None\n",
    "                continue\n",
    "            else:\n",
    "                no_data = False\n",
    "            loss = grpo_loss(**training_data)\n",
    "        #print(f\"step {i} loss is {loss}\")\n",
    "        if total_loss is None:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss += loss\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    game_lengths_all = game_statistics['game_lengths_all']\n",
    "    game_length_avg = sum(game_lengths_all)/len(game_lengths_all)\n",
    "    game_lengths_draw = game_statistics['game_lengths_draws']\n",
    "    num_draws = len(game_lengths_draw)\n",
    "    draw_length_avg = sum(game_lengths_draw)/num_draws\n",
    "    print(f\"{j} end iteration loss: {total_loss}, game_length_avg: {game_length_avg}, draw_length_avg: {draw_length_avg}, num_draws: {num_draws}/{len(game_lengths_all)}\")\n",
    "\n",
    "def multi_agent_trainer(model):\n",
    "    optimizer = Adam(model.parameters(),lr=0.001)\n",
    "    model.train()\n",
    "    opponent = SimpleMahjongAgent()\n",
    "    #opponent = DumbMahjongAgent()\n",
    "    # get rollouts/episodes\n",
    "    for epoch in range(100):\n",
    "        game_statistics = {'game_lengths_all': [], 'game_lengths_draws': []}\n",
    "        wins = 0\n",
    "        rewards = []\n",
    "        log_probs_totals = []\n",
    "        for i in range(400):\n",
    "            no_data = True\n",
    "            while no_data:\n",
    "                agent = NetMahjongAgentTrainingV2(model)\n",
    "                training_data = multi_agent_game_manager(agent,opponent,game_statistics)\n",
    "                if training_data is None: # if we want to exclude this game from training, game_manager should return None\n",
    "                    continue\n",
    "                else:\n",
    "                    no_data = False\n",
    "                wins += training_data['win']\n",
    "                if training_data['log_probs']:\n",
    "                    rewards.append(training_data['reward'])\n",
    "                    log_probs_totals.append(torch.hstack(training_data['log_probs']).sum())\n",
    "        # compute standardized advantage\n",
    "        reward_tensor = torch.tensor(rewards)\n",
    "        reward_mean = reward_tensor.mean()\n",
    "        reward_std = reward_tensor.std()\n",
    "        advantage = (reward_tensor-reward_mean)/reward_std\n",
    "        log_probs_totals_tensor = torch.hstack(log_probs_totals)\n",
    "        # grpo loss\n",
    "        loss = -(advantage*log_probs_totals_tensor).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        game_lengths_all = game_statistics['game_lengths_all']\n",
    "        game_length_avg = sum(game_lengths_all)/len(game_lengths_all)\n",
    "        game_lengths_draw = game_statistics['game_lengths_draws']\n",
    "        num_draws = len(game_lengths_draw)\n",
    "        draw_length_avg = sum(game_lengths_draw)/num_draws\n",
    "        #print(log_probs_totals_tensor)\n",
    "        #print(advantage)\n",
    "        print(f\"{epoch} end iteration loss: {loss}, wins: {wins}, game_length_avg: {game_length_avg}, draw_length_avg: {draw_length_avg}, num_draws: {num_draws}/{len(game_lengths_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d437af5d-eb83-4f0a-b64d-64e3d4888adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocabulary_size': 18, 'embedding_size': 17, 'batch_size': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PinoyMahjongNet(\n",
       "  (embeddings): Embedding(18, 17)\n",
       "  (tokenization): Linear(in_features=17, out_features=18, bias=False)\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=34, out_features=34, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=34, out_features=34, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=34, out_features=34, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=34, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tiles_list)\n",
    "embedding_size = vocabulary_size-int(math.log10(vocabulary_size))\n",
    "hand_size = 5\n",
    "batch_size = 1\n",
    "hp = {\n",
    "    'vocabulary_size': vocabulary_size,\n",
    "    'embedding_size': embedding_size,\n",
    "    'batch_size': batch_size,\n",
    "}\n",
    "print(hp)\n",
    "model = PinoyMahjongNet(hp)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7dece9f2-8a5e-44b9-99a9-af5cd2aef3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 end iteration loss: -352.9567565917969, wins: 21, game_length_avg: 90.91, draw_length_avg: 110.61764705882354, num_draws: 136/200\n",
      "1 end iteration loss: -360.40057373046875, wins: 18, game_length_avg: 92.85, draw_length_avg: 110.53521126760563, num_draws: 142/200\n",
      "2 end iteration loss: -152.31893920898438, wins: 12, game_length_avg: 92.24, draw_length_avg: 110.76811594202898, num_draws: 138/200\n",
      "3 end iteration loss: -424.6858215332031, wins: 19, game_length_avg: 95.22, draw_length_avg: 110.79194630872483, num_draws: 149/200\n",
      "4 end iteration loss: -197.89993286132812, wins: 24, game_length_avg: 92.71, draw_length_avg: 110.94202898550725, num_draws: 138/200\n",
      "5 end iteration loss: -198.65623474121094, wins: 16, game_length_avg: 93.35, draw_length_avg: 110.67142857142858, num_draws: 140/200\n",
      "6 end iteration loss: -251.2693328857422, wins: 18, game_length_avg: 93.24, draw_length_avg: 110.68055555555556, num_draws: 144/200\n",
      "7 end iteration loss: -415.1628112792969, wins: 20, game_length_avg: 91.16, draw_length_avg: 110.77142857142857, num_draws: 140/200\n",
      "8 end iteration loss: -366.46246337890625, wins: 26, game_length_avg: 88.21, draw_length_avg: 110.69172932330827, num_draws: 133/200\n",
      "9 end iteration loss: -270.1153564453125, wins: 21, game_length_avg: 92.66, draw_length_avg: 110.69565217391305, num_draws: 138/200\n",
      "10 end iteration loss: -371.7553405761719, wins: 26, game_length_avg: 91.61, draw_length_avg: 110.72307692307692, num_draws: 130/200\n",
      "11 end iteration loss: -363.4081726074219, wins: 21, game_length_avg: 94.32, draw_length_avg: 110.6086956521739, num_draws: 138/200\n",
      "12 end iteration loss: -267.0694885253906, wins: 16, game_length_avg: 92.57, draw_length_avg: 110.65185185185184, num_draws: 135/200\n",
      "13 end iteration loss: -428.9744567871094, wins: 28, game_length_avg: 89.5, draw_length_avg: 110.75555555555556, num_draws: 135/200\n",
      "14 end iteration loss: -343.58782958984375, wins: 24, game_length_avg: 90.8, draw_length_avg: 110.78832116788321, num_draws: 137/200\n",
      "15 end iteration loss: -388.0152893066406, wins: 22, game_length_avg: 95.03, draw_length_avg: 110.83561643835617, num_draws: 146/200\n",
      "16 end iteration loss: -292.4999084472656, wins: 20, game_length_avg: 94.22, draw_length_avg: 110.87671232876713, num_draws: 146/200\n",
      "17 end iteration loss: -425.2465515136719, wins: 30, game_length_avg: 89.23, draw_length_avg: 110.73282442748092, num_draws: 131/200\n",
      "18 end iteration loss: -256.58197021484375, wins: 24, game_length_avg: 90.86, draw_length_avg: 110.83211678832117, num_draws: 137/200\n",
      "19 end iteration loss: -265.5009765625, wins: 18, game_length_avg: 94.64, draw_length_avg: 110.9103448275862, num_draws: 145/200\n",
      "20 end iteration loss: -153.94464111328125, wins: 21, game_length_avg: 95.85, draw_length_avg: 110.8951048951049, num_draws: 143/200\n",
      "21 end iteration loss: -377.592529296875, wins: 20, game_length_avg: 93.51, draw_length_avg: 110.74820143884892, num_draws: 139/200\n",
      "22 end iteration loss: -147.23855590820312, wins: 17, game_length_avg: 93.19, draw_length_avg: 110.93706293706293, num_draws: 143/200\n",
      "23 end iteration loss: -327.47882080078125, wins: 23, game_length_avg: 93.43, draw_length_avg: 110.80851063829788, num_draws: 141/200\n",
      "24 end iteration loss: -282.9765625, wins: 20, game_length_avg: 94.21, draw_length_avg: 110.95774647887323, num_draws: 142/200\n",
      "25 end iteration loss: -308.830810546875, wins: 23, game_length_avg: 94.79, draw_length_avg: 110.77777777777777, num_draws: 144/200\n",
      "26 end iteration loss: -372.83831787109375, wins: 20, game_length_avg: 95.4, draw_length_avg: 110.89189189189189, num_draws: 148/200\n",
      "27 end iteration loss: -373.1720886230469, wins: 19, game_length_avg: 95.77, draw_length_avg: 110.97402597402598, num_draws: 154/200\n",
      "28 end iteration loss: -304.0301513671875, wins: 22, game_length_avg: 93.98, draw_length_avg: 110.78321678321679, num_draws: 143/200\n",
      "29 end iteration loss: -268.5687255859375, wins: 18, game_length_avg: 95.97, draw_length_avg: 110.97902097902097, num_draws: 143/200\n",
      "30 end iteration loss: -513.78955078125, wins: 30, game_length_avg: 90.16, draw_length_avg: 110.64179104477611, num_draws: 134/200\n",
      "31 end iteration loss: -119.9004898071289, wins: 17, game_length_avg: 89.93, draw_length_avg: 111.19117647058823, num_draws: 136/200\n",
      "32 end iteration loss: -90.05996704101562, wins: 12, game_length_avg: 94.7, draw_length_avg: 110.97872340425532, num_draws: 141/200\n",
      "33 end iteration loss: -177.9755401611328, wins: 16, game_length_avg: 91.52, draw_length_avg: 110.77037037037037, num_draws: 135/200\n",
      "34 end iteration loss: -106.23223114013672, wins: 19, game_length_avg: 91.69, draw_length_avg: 111.07913669064749, num_draws: 139/200\n",
      "35 end iteration loss: -346.60162353515625, wins: 24, game_length_avg: 94.81, draw_length_avg: 111.0, num_draws: 136/200\n",
      "36 end iteration loss: -137.56126403808594, wins: 23, game_length_avg: 94.08, draw_length_avg: 110.69565217391305, num_draws: 138/200\n",
      "37 end iteration loss: -170.38584899902344, wins: 15, game_length_avg: 92.89, draw_length_avg: 110.93525179856115, num_draws: 139/200\n",
      "38 end iteration loss: -217.5732421875, wins: 15, game_length_avg: 93.05, draw_length_avg: 110.9645390070922, num_draws: 141/200\n",
      "39 end iteration loss: -354.5246887207031, wins: 29, game_length_avg: 91.94, draw_length_avg: 110.94117647058823, num_draws: 136/200\n",
      "40 end iteration loss: -267.5643310546875, wins: 19, game_length_avg: 92.25, draw_length_avg: 111.00709219858156, num_draws: 141/200\n",
      "41 end iteration loss: -305.257080078125, wins: 16, game_length_avg: 94.89, draw_length_avg: 110.96598639455782, num_draws: 147/200\n",
      "42 end iteration loss: -280.95166015625, wins: 21, game_length_avg: 94.26, draw_length_avg: 111.05633802816901, num_draws: 142/200\n",
      "43 end iteration loss: -508.2679443359375, wins: 29, game_length_avg: 90.21, draw_length_avg: 110.91044776119404, num_draws: 134/200\n",
      "44 end iteration loss: -266.05609130859375, wins: 21, game_length_avg: 92.49, draw_length_avg: 110.796992481203, num_draws: 133/200\n",
      "45 end iteration loss: -191.27748107910156, wins: 23, game_length_avg: 89.36, draw_length_avg: 111.17829457364341, num_draws: 129/200\n",
      "46 end iteration loss: -240.1846160888672, wins: 18, game_length_avg: 97.01, draw_length_avg: 110.86111111111111, num_draws: 144/200\n",
      "47 end iteration loss: -364.6932067871094, wins: 30, game_length_avg: 86.18, draw_length_avg: 110.75, num_draws: 128/200\n",
      "48 end iteration loss: -293.6158447265625, wins: 30, game_length_avg: 91.77, draw_length_avg: 111.08396946564885, num_draws: 131/200\n",
      "49 end iteration loss: -353.339599609375, wins: 18, game_length_avg: 93.65, draw_length_avg: 110.93877551020408, num_draws: 147/200\n",
      "50 end iteration loss: -359.60400390625, wins: 29, game_length_avg: 93.45, draw_length_avg: 111.13432835820896, num_draws: 134/200\n",
      "51 end iteration loss: -244.41534423828125, wins: 20, game_length_avg: 95.64, draw_length_avg: 110.9103448275862, num_draws: 145/200\n",
      "52 end iteration loss: -441.8459167480469, wins: 22, game_length_avg: 95.87, draw_length_avg: 110.95945945945945, num_draws: 148/200\n",
      "53 end iteration loss: -323.23419189453125, wins: 16, game_length_avg: 95.0, draw_length_avg: 111.0909090909091, num_draws: 143/200\n",
      "54 end iteration loss: -350.76361083984375, wins: 26, game_length_avg: 90.05, draw_length_avg: 111.15384615384616, num_draws: 130/200\n",
      "55 end iteration loss: -401.35784912109375, wins: 27, game_length_avg: 90.31, draw_length_avg: 110.82608695652173, num_draws: 138/200\n",
      "56 end iteration loss: -360.4586181640625, wins: 30, game_length_avg: 91.79, draw_length_avg: 111.02985074626865, num_draws: 134/200\n",
      "57 end iteration loss: -369.141357421875, wins: 21, game_length_avg: 96.07, draw_length_avg: 111.10344827586206, num_draws: 145/200\n",
      "58 end iteration loss: -347.61627197265625, wins: 19, game_length_avg: 93.14, draw_length_avg: 111.0, num_draws: 140/200\n",
      "59 end iteration loss: -216.67434692382812, wins: 27, game_length_avg: 96.83, draw_length_avg: 111.29577464788733, num_draws: 142/200\n",
      "60 end iteration loss: -340.32159423828125, wins: 32, game_length_avg: 91.29, draw_length_avg: 111.05511811023622, num_draws: 127/200\n",
      "61 end iteration loss: -205.7178497314453, wins: 17, game_length_avg: 94.32, draw_length_avg: 111.34306569343066, num_draws: 137/200\n",
      "62 end iteration loss: -290.0387268066406, wins: 23, game_length_avg: 90.87, draw_length_avg: 111.14925373134328, num_draws: 134/200\n",
      "63 end iteration loss: -285.6942138671875, wins: 22, game_length_avg: 93.34, draw_length_avg: 111.37062937062937, num_draws: 143/200\n",
      "64 end iteration loss: -455.7455749511719, wins: 32, game_length_avg: 89.23, draw_length_avg: 111.22137404580153, num_draws: 131/200\n",
      "65 end iteration loss: -321.919677734375, wins: 27, game_length_avg: 93.5, draw_length_avg: 111.38888888888889, num_draws: 144/200\n",
      "66 end iteration loss: -250.558349609375, wins: 30, game_length_avg: 92.52, draw_length_avg: 111.16923076923077, num_draws: 130/200\n",
      "67 end iteration loss: -352.92767333984375, wins: 30, game_length_avg: 90.11, draw_length_avg: 111.11940298507463, num_draws: 134/200\n",
      "68 end iteration loss: -352.0986328125, wins: 27, game_length_avg: 92.01, draw_length_avg: 111.26618705035972, num_draws: 139/200\n",
      "69 end iteration loss: -324.7169494628906, wins: 27, game_length_avg: 92.5, draw_length_avg: 111.171875, num_draws: 128/200\n",
      "70 end iteration loss: -321.33203125, wins: 34, game_length_avg: 94.22, draw_length_avg: 111.1830985915493, num_draws: 142/200\n",
      "71 end iteration loss: -285.0784912109375, wins: 33, game_length_avg: 89.95, draw_length_avg: 111.19672131147541, num_draws: 122/200\n",
      "72 end iteration loss: -330.4164123535156, wins: 22, game_length_avg: 96.06, draw_length_avg: 111.41095890410959, num_draws: 146/200\n",
      "73 end iteration loss: -425.52471923828125, wins: 27, game_length_avg: 95.23, draw_length_avg: 111.24475524475524, num_draws: 143/200\n",
      "74 end iteration loss: -197.88119506835938, wins: 29, game_length_avg: 92.51, draw_length_avg: 111.53125, num_draws: 128/200\n",
      "75 end iteration loss: -330.81988525390625, wins: 29, game_length_avg: 88.35, draw_length_avg: 111.408, num_draws: 125/200\n",
      "76 end iteration loss: -319.1056213378906, wins: 31, game_length_avg: 92.02, draw_length_avg: 111.45185185185186, num_draws: 135/200\n",
      "77 end iteration loss: -372.88616943359375, wins: 27, game_length_avg: 89.66, draw_length_avg: 111.35338345864662, num_draws: 133/200\n",
      "78 end iteration loss: -266.3146667480469, wins: 27, game_length_avg: 91.41, draw_length_avg: 111.55555555555556, num_draws: 135/200\n",
      "79 end iteration loss: -241.72988891601562, wins: 40, game_length_avg: 95.08, draw_length_avg: 111.53731343283582, num_draws: 134/200\n",
      "80 end iteration loss: -317.5570983886719, wins: 31, game_length_avg: 89.66, draw_length_avg: 111.34375, num_draws: 128/200\n",
      "81 end iteration loss: -283.33349609375, wins: 40, game_length_avg: 93.22, draw_length_avg: 111.68656716417911, num_draws: 134/200\n",
      "82 end iteration loss: -331.8787841796875, wins: 29, game_length_avg: 87.83, draw_length_avg: 111.17460317460318, num_draws: 126/200\n",
      "83 end iteration loss: -351.2908935546875, wins: 28, game_length_avg: 93.03, draw_length_avg: 111.58518518518518, num_draws: 135/200\n",
      "84 end iteration loss: -437.7752685546875, wins: 35, game_length_avg: 91.92, draw_length_avg: 111.60583941605839, num_draws: 137/200\n",
      "85 end iteration loss: -324.827392578125, wins: 42, game_length_avg: 87.32, draw_length_avg: 111.5609756097561, num_draws: 123/200\n",
      "86 end iteration loss: -275.7618408203125, wins: 31, game_length_avg: 94.54, draw_length_avg: 111.8529411764706, num_draws: 136/200\n",
      "87 end iteration loss: -304.77197265625, wins: 29, game_length_avg: 91.77, draw_length_avg: 111.73722627737226, num_draws: 137/200\n",
      "88 end iteration loss: -234.78656005859375, wins: 32, game_length_avg: 92.62, draw_length_avg: 111.86764705882354, num_draws: 136/200\n",
      "89 end iteration loss: -295.5027160644531, wins: 34, game_length_avg: 84.31, draw_length_avg: 111.86440677966101, num_draws: 118/200\n",
      "90 end iteration loss: -120.98941040039062, wins: 40, game_length_avg: 88.85, draw_length_avg: 111.70491803278688, num_draws: 122/200\n",
      "91 end iteration loss: -133.28164672851562, wins: 29, game_length_avg: 93.77, draw_length_avg: 111.71851851851852, num_draws: 135/200\n",
      "92 end iteration loss: -218.15042114257812, wins: 42, game_length_avg: 83.37, draw_length_avg: 111.9327731092437, num_draws: 119/200\n",
      "93 end iteration loss: -218.55645751953125, wins: 42, game_length_avg: 89.71, draw_length_avg: 111.86440677966101, num_draws: 118/200\n",
      "94 end iteration loss: -174.05479431152344, wins: 52, game_length_avg: 82.4, draw_length_avg: 112.0, num_draws: 103/200\n",
      "95 end iteration loss: -72.34272766113281, wins: 42, game_length_avg: 84.0, draw_length_avg: 111.67924528301887, num_draws: 106/200\n",
      "96 end iteration loss: -201.42498779296875, wins: 39, game_length_avg: 90.69, draw_length_avg: 111.96899224806202, num_draws: 129/200\n",
      "97 end iteration loss: -75.92854309082031, wins: 28, game_length_avg: 89.52, draw_length_avg: 111.796875, num_draws: 128/200\n",
      "98 end iteration loss: -167.45726013183594, wins: 44, game_length_avg: 87.74, draw_length_avg: 111.94782608695652, num_draws: 115/200\n",
      "99 end iteration loss: -163.2474822998047, wins: 39, game_length_avg: 90.61, draw_length_avg: 111.98387096774194, num_draws: 124/200\n"
     ]
    }
   ],
   "source": [
    "model = PinoyMahjongNet(hp)\n",
    "multi_agent_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0ec663e3-74c4-497a-8132-260f39ef391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/_9/0bl8t2fd4dnfgskt322pjttc0000gn/T/ipykernel_15839/224881488.py\u001b[0m(99)\u001b[0;36maction1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     97 \u001b[0;31m                \u001b[0mhand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 99 \u001b[0;31m            \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  hand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1b', '4s', '2b', '3s']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  top_discard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3b'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s_chow\n",
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "13e191f6-bd32-4c56-8b4f-d9eb8bb188d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 end iteration loss: -16.0616512298584, wins: 108, game_length_avg: 82.895, draw_length_avg: 114.19047619047619, num_draws: 189/400\n",
      "1 end iteration loss: -48.29631805419922, wins: 89, game_length_avg: 86.88, draw_length_avg: 114.2085308056872, num_draws: 211/400\n",
      "2 end iteration loss: 0.8633313179016113, wins: 111, game_length_avg: 87.575, draw_length_avg: 114.32835820895522, num_draws: 201/400\n",
      "3 end iteration loss: -6.712360382080078, wins: 111, game_length_avg: 84.21, draw_length_avg: 114.17647058823529, num_draws: 204/400\n",
      "4 end iteration loss: -41.66496276855469, wins: 104, game_length_avg: 88.44, draw_length_avg: 114.01941747572816, num_draws: 206/400\n",
      "5 end iteration loss: -10.485408782958984, wins: 111, game_length_avg: 85.25, draw_length_avg: 114.29292929292929, num_draws: 198/400\n",
      "6 end iteration loss: -52.822059631347656, wins: 103, game_length_avg: 86.175, draw_length_avg: 114.34482758620689, num_draws: 203/400\n",
      "7 end iteration loss: -42.11555480957031, wins: 107, game_length_avg: 84.855, draw_length_avg: 114.3743842364532, num_draws: 203/400\n",
      "8 end iteration loss: -40.670631408691406, wins: 98, game_length_avg: 89.63, draw_length_avg: 114.08294930875576, num_draws: 217/400\n",
      "9 end iteration loss: -18.194622039794922, wins: 95, game_length_avg: 88.46, draw_length_avg: 113.79439252336448, num_draws: 214/400\n",
      "10 end iteration loss: 2.2202396392822266, wins: 111, game_length_avg: 86.27, draw_length_avg: 114.04040404040404, num_draws: 198/400\n",
      "11 end iteration loss: -49.24650955200195, wins: 110, game_length_avg: 83.585, draw_length_avg: 114.21857923497268, num_draws: 183/400\n",
      "12 end iteration loss: -39.988861083984375, wins: 106, game_length_avg: 86.35, draw_length_avg: 114.21319796954315, num_draws: 197/400\n",
      "13 end iteration loss: -66.23558044433594, wins: 108, game_length_avg: 84.87, draw_length_avg: 113.71144278606965, num_draws: 201/400\n",
      "14 end iteration loss: -3.988469123840332, wins: 117, game_length_avg: 85.835, draw_length_avg: 114.2741116751269, num_draws: 197/400\n",
      "15 end iteration loss: -95.8911361694336, wins: 115, game_length_avg: 86.38, draw_length_avg: 114.16585365853659, num_draws: 205/400\n",
      "16 end iteration loss: -5.290521621704102, wins: 114, game_length_avg: 84.79, draw_length_avg: 114.37696335078535, num_draws: 191/400\n",
      "17 end iteration loss: -33.286537170410156, wins: 116, game_length_avg: 85.43, draw_length_avg: 114.39583333333333, num_draws: 192/400\n",
      "18 end iteration loss: -41.048309326171875, wins: 102, game_length_avg: 86.5, draw_length_avg: 114.23, num_draws: 200/400\n",
      "19 end iteration loss: -37.555030822753906, wins: 92, game_length_avg: 89.96, draw_length_avg: 113.79723502304148, num_draws: 217/400\n",
      "20 end iteration loss: -38.507442474365234, wins: 111, game_length_avg: 85.34, draw_length_avg: 114.27225130890052, num_draws: 191/400\n",
      "21 end iteration loss: -41.28046417236328, wins: 101, game_length_avg: 86.47, draw_length_avg: 114.37254901960785, num_draws: 204/400\n",
      "22 end iteration loss: -75.1636962890625, wins: 105, game_length_avg: 87.025, draw_length_avg: 114.20588235294117, num_draws: 204/400\n",
      "23 end iteration loss: -94.3692626953125, wins: 103, game_length_avg: 86.955, draw_length_avg: 114.10377358490567, num_draws: 212/400\n",
      "24 end iteration loss: -27.922510147094727, wins: 101, game_length_avg: 85.65, draw_length_avg: 114.39024390243902, num_draws: 205/400\n",
      "25 end iteration loss: -54.39765167236328, wins: 105, game_length_avg: 85.305, draw_length_avg: 114.30927835051547, num_draws: 194/400\n",
      "26 end iteration loss: -58.82717514038086, wins: 105, game_length_avg: 84.53, draw_length_avg: 114.24365482233503, num_draws: 197/400\n",
      "27 end iteration loss: -37.47340393066406, wins: 91, game_length_avg: 85.065, draw_length_avg: 114.17391304347827, num_draws: 207/400\n",
      "28 end iteration loss: -40.72317886352539, wins: 107, game_length_avg: 84.82, draw_length_avg: 114.06091370558376, num_draws: 197/400\n",
      "29 end iteration loss: -51.52671813964844, wins: 92, game_length_avg: 85.255, draw_length_avg: 114.31472081218274, num_draws: 197/400\n",
      "30 end iteration loss: 12.401322364807129, wins: 101, game_length_avg: 86.245, draw_length_avg: 114.23880597014926, num_draws: 201/400\n",
      "31 end iteration loss: -40.781375885009766, wins: 104, game_length_avg: 88.375, draw_length_avg: 114.27777777777777, num_draws: 216/400\n",
      "32 end iteration loss: -84.92120361328125, wins: 105, game_length_avg: 88.545, draw_length_avg: 114.15686274509804, num_draws: 204/400\n",
      "33 end iteration loss: -59.046669006347656, wins: 119, game_length_avg: 86.47, draw_length_avg: 114.28865979381443, num_draws: 194/400\n",
      "34 end iteration loss: -53.90380859375, wins: 122, game_length_avg: 82.105, draw_length_avg: 114.29213483146067, num_draws: 178/400\n",
      "35 end iteration loss: -68.868896484375, wins: 108, game_length_avg: 86.39, draw_length_avg: 114.28282828282828, num_draws: 198/400\n",
      "36 end iteration loss: -65.56370544433594, wins: 109, game_length_avg: 84.735, draw_length_avg: 114.13, num_draws: 200/400\n",
      "37 end iteration loss: -78.28874969482422, wins: 100, game_length_avg: 85.09, draw_length_avg: 114.62439024390244, num_draws: 205/400\n",
      "38 end iteration loss: -54.987060546875, wins: 111, game_length_avg: 82.92, draw_length_avg: 114.22950819672131, num_draws: 183/400\n",
      "39 end iteration loss: -80.97943115234375, wins: 118, game_length_avg: 87.095, draw_length_avg: 114.38144329896907, num_draws: 194/400\n",
      "40 end iteration loss: -1.1611976623535156, wins: 106, game_length_avg: 85.0, draw_length_avg: 114.33673469387755, num_draws: 196/400\n",
      "41 end iteration loss: -22.72815704345703, wins: 111, game_length_avg: 85.05, draw_length_avg: 113.90816326530613, num_draws: 196/400\n",
      "42 end iteration loss: -7.218163967132568, wins: 97, game_length_avg: 86.0, draw_length_avg: 113.97058823529412, num_draws: 204/400\n",
      "43 end iteration loss: -32.98487854003906, wins: 105, game_length_avg: 84.945, draw_length_avg: 114.2871287128713, num_draws: 202/400\n",
      "44 end iteration loss: -63.247623443603516, wins: 91, game_length_avg: 84.755, draw_length_avg: 114.13793103448276, num_draws: 203/400\n",
      "45 end iteration loss: -39.562767028808594, wins: 114, game_length_avg: 84.29, draw_length_avg: 114.26262626262626, num_draws: 198/400\n",
      "46 end iteration loss: -32.49652862548828, wins: 88, game_length_avg: 87.475, draw_length_avg: 114.54625550660793, num_draws: 227/400\n",
      "47 end iteration loss: -81.52326965332031, wins: 103, game_length_avg: 89.63, draw_length_avg: 114.08181818181818, num_draws: 220/400\n",
      "48 end iteration loss: -35.99176788330078, wins: 99, game_length_avg: 87.56, draw_length_avg: 114.34741784037558, num_draws: 213/400\n",
      "49 end iteration loss: -28.30000114440918, wins: 99, game_length_avg: 86.135, draw_length_avg: 114.12807881773399, num_draws: 203/400\n",
      "50 end iteration loss: -8.613239288330078, wins: 104, game_length_avg: 86.28, draw_length_avg: 114.06896551724138, num_draws: 203/400\n",
      "51 end iteration loss: -38.75590896606445, wins: 99, game_length_avg: 86.935, draw_length_avg: 114.60287081339713, num_draws: 209/400\n",
      "52 end iteration loss: -28.99116325378418, wins: 111, game_length_avg: 84.88, draw_length_avg: 114.12182741116752, num_draws: 197/400\n",
      "53 end iteration loss: -9.885056495666504, wins: 113, game_length_avg: 86.25, draw_length_avg: 114.40837696335079, num_draws: 191/400\n",
      "54 end iteration loss: -28.322830200195312, wins: 87, game_length_avg: 88.025, draw_length_avg: 114.22330097087378, num_draws: 206/400\n",
      "55 end iteration loss: -46.783939361572266, wins: 116, game_length_avg: 87.08, draw_length_avg: 114.5959595959596, num_draws: 198/400\n",
      "56 end iteration loss: -24.39314842224121, wins: 106, game_length_avg: 84.385, draw_length_avg: 114.42424242424242, num_draws: 198/400\n",
      "57 end iteration loss: 5.337475776672363, wins: 99, game_length_avg: 85.89, draw_length_avg: 113.8529411764706, num_draws: 204/400\n",
      "58 end iteration loss: -45.76327896118164, wins: 114, game_length_avg: 84.61, draw_length_avg: 114.5, num_draws: 192/400\n",
      "59 end iteration loss: -31.350181579589844, wins: 100, game_length_avg: 82.795, draw_length_avg: 113.54545454545455, num_draws: 198/400\n",
      "60 end iteration loss: -67.90115356445312, wins: 103, game_length_avg: 87.765, draw_length_avg: 114.20588235294117, num_draws: 204/400\n",
      "61 end iteration loss: -56.970584869384766, wins: 102, game_length_avg: 86.15, draw_length_avg: 114.16831683168317, num_draws: 202/400\n",
      "62 end iteration loss: -57.70880889892578, wins: 113, game_length_avg: 84.47, draw_length_avg: 114.03061224489795, num_draws: 196/400\n",
      "63 end iteration loss: -55.68109893798828, wins: 94, game_length_avg: 85.335, draw_length_avg: 114.04784688995215, num_draws: 209/400\n",
      "64 end iteration loss: -39.54563522338867, wins: 99, game_length_avg: 86.675, draw_length_avg: 114.47887323943662, num_draws: 213/400\n",
      "65 end iteration loss: -35.5455207824707, wins: 112, game_length_avg: 83.83, draw_length_avg: 113.78947368421052, num_draws: 190/400\n",
      "66 end iteration loss: -47.12110900878906, wins: 120, game_length_avg: 86.29, draw_length_avg: 113.8984771573604, num_draws: 197/400\n",
      "67 end iteration loss: -33.90406799316406, wins: 102, game_length_avg: 84.68, draw_length_avg: 114.15384615384616, num_draws: 195/400\n",
      "68 end iteration loss: -68.79594421386719, wins: 103, game_length_avg: 86.575, draw_length_avg: 114.34482758620689, num_draws: 203/400\n",
      "69 end iteration loss: -14.886080741882324, wins: 110, game_length_avg: 87.595, draw_length_avg: 114.14, num_draws: 200/400\n",
      "70 end iteration loss: -1.7553212642669678, wins: 105, game_length_avg: 86.535, draw_length_avg: 114.16042780748663, num_draws: 187/400\n",
      "71 end iteration loss: -14.37928581237793, wins: 116, game_length_avg: 85.19, draw_length_avg: 114.16494845360825, num_draws: 194/400\n",
      "72 end iteration loss: -17.272621154785156, wins: 114, game_length_avg: 85.005, draw_length_avg: 114.63874345549738, num_draws: 191/400\n",
      "73 end iteration loss: -44.591209411621094, wins: 89, game_length_avg: 86.705, draw_length_avg: 114.26923076923077, num_draws: 208/400\n",
      "74 end iteration loss: -33.73439025878906, wins: 98, game_length_avg: 84.2, draw_length_avg: 113.89795918367346, num_draws: 196/400\n",
      "75 end iteration loss: -50.80706024169922, wins: 98, game_length_avg: 87.055, draw_length_avg: 113.9423076923077, num_draws: 208/400\n",
      "76 end iteration loss: -78.84871673583984, wins: 93, game_length_avg: 85.655, draw_length_avg: 114.43062200956938, num_draws: 209/400\n",
      "77 end iteration loss: -32.92181396484375, wins: 105, game_length_avg: 87.555, draw_length_avg: 114.31632653061224, num_draws: 196/400\n",
      "78 end iteration loss: -67.57096099853516, wins: 103, game_length_avg: 87.155, draw_length_avg: 114.1078431372549, num_draws: 204/400\n",
      "79 end iteration loss: -63.419586181640625, wins: 105, game_length_avg: 83.285, draw_length_avg: 113.875, num_draws: 192/400\n",
      "80 end iteration loss: -23.36599349975586, wins: 108, game_length_avg: 85.675, draw_length_avg: 114.34482758620689, num_draws: 203/400\n",
      "81 end iteration loss: -92.27082061767578, wins: 109, game_length_avg: 83.945, draw_length_avg: 114.26881720430107, num_draws: 186/400\n",
      "82 end iteration loss: -59.066139221191406, wins: 109, game_length_avg: 84.96, draw_length_avg: 114.52, num_draws: 200/400\n",
      "83 end iteration loss: -49.78704071044922, wins: 104, game_length_avg: 88.46, draw_length_avg: 114.02857142857142, num_draws: 210/400\n",
      "84 end iteration loss: 28.65601348876953, wins: 95, game_length_avg: 86.005, draw_length_avg: 114.23232323232324, num_draws: 198/400\n",
      "85 end iteration loss: -45.02961730957031, wins: 99, game_length_avg: 85.97, draw_length_avg: 114.02010050251256, num_draws: 199/400\n",
      "86 end iteration loss: 1.6034221649169922, wins: 112, game_length_avg: 82.35, draw_length_avg: 114.07650273224044, num_draws: 183/400\n",
      "87 end iteration loss: -29.892009735107422, wins: 110, game_length_avg: 84.955, draw_length_avg: 114.00980392156863, num_draws: 204/400\n",
      "88 end iteration loss: -13.245072364807129, wins: 119, game_length_avg: 82.88, draw_length_avg: 114.2127659574468, num_draws: 188/400\n",
      "89 end iteration loss: -55.9268798828125, wins: 100, game_length_avg: 87.92, draw_length_avg: 114.39234449760765, num_draws: 209/400\n",
      "90 end iteration loss: -36.887210845947266, wins: 115, game_length_avg: 86.84, draw_length_avg: 114.16580310880829, num_draws: 193/400\n",
      "91 end iteration loss: -18.676265716552734, wins: 107, game_length_avg: 84.49, draw_length_avg: 114.35897435897436, num_draws: 195/400\n",
      "92 end iteration loss: -38.441184997558594, wins: 112, game_length_avg: 86.2, draw_length_avg: 114.54639175257732, num_draws: 194/400\n",
      "93 end iteration loss: -57.04007339477539, wins: 113, game_length_avg: 81.68, draw_length_avg: 114.14689265536722, num_draws: 177/400\n",
      "94 end iteration loss: -55.19784927368164, wins: 99, game_length_avg: 87.665, draw_length_avg: 114.11374407582939, num_draws: 211/400\n",
      "95 end iteration loss: -27.3432559967041, wins: 115, game_length_avg: 84.125, draw_length_avg: 114.74193548387096, num_draws: 186/400\n",
      "96 end iteration loss: -5.676668167114258, wins: 111, game_length_avg: 85.595, draw_length_avg: 114.59574468085107, num_draws: 188/400\n",
      "97 end iteration loss: -55.731689453125, wins: 112, game_length_avg: 85.84, draw_length_avg: 114.18811881188118, num_draws: 202/400\n",
      "98 end iteration loss: -11.775104522705078, wins: 97, game_length_avg: 85.29, draw_length_avg: 114.48275862068965, num_draws: 203/400\n",
      "99 end iteration loss: 4.864432334899902, wins: 93, game_length_avg: 87.255, draw_length_avg: 114.21463414634147, num_draws: 205/400\n"
     ]
    }
   ],
   "source": [
    "multi_agent_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "21b08f63-9224-434f-adb7-bd5edd5768ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/_9/0bl8t2fd4dnfgskt322pjttc0000gn/T/ipykernel_15839/806113209.py\u001b[0m(99)\u001b[0;36maction1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     97 \u001b[0;31m                \u001b[0mhand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 99 \u001b[0;31m            \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  matching_suit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'matching_suit' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  hand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5b']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pickup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'pickup' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s_chow\n",
      "ipdb>  choice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pickup'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  top_discard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'5b'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deck': ['1s', '4b', '6s', '8s', '2b', '5b', '6b', '2b', '1s', '5s', '9s', '6b', '7s', '9b', '7s', '3s', '4b', '2b', '5b', '5s', '5s', '1b', '2s', '8b', '4s', '2b', '9b', '2s', '2s', '3b', '4b', '9s', '4b', '7s', '7s', '7b', '6s', '1b', '7b', '9s', '9b', '1s', '1b', '8b', '8s', '4s', '1s', '8b', '8s', '6s', '6b', '9s', '6s'], 'discard': ['6b', '3s'], 'n': ['7b', '3b', '3b', '3b'], 'e': ['5b'], 's': ['7b', '9b', '8s', '1b'], 'w': ['8b'], 'N': [], 'E': ['3s', '4s', '5s'], 'S': [], 'W': ['2s', '3s', '4s'], 'turn': 'e'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  narration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'narration' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "71af17ac-b44c-4151-893c-cd11ad1b5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'prototype_18t_v0.pth')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "01b9d0d4-a94a-401b-af60-3d47fc4d720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 'awaiting player n to discard' n ['1b', '7b', '6b', '6s', '9b'] []\n",
      "1 'player e must draw' e ['6b', '3s', '2b', '3s'] ['1b']\n",
      "2 'awaiting player e to discard' e ['6b', '3s', '2b', '3s', '9b'] ['1b']\n",
      "3 'player s must draw' s ['5b', '9s', '6s', '7s'] ['9b']\n",
      "4 'awaiting player s to discard' s ['5b', '9s', '6s', '7s', '5s'] ['9b']\n",
      "5 'player w must draw' w ['7s', '2b', '8b', '3b'] ['5s']\n",
      "6 'awaiting player w to discard' w ['7s', '2b', '8b', '3b', '7s'] ['5s']\n",
      "7 'player n must draw' n ['7b', '6b', '6s', '9b'] ['3b']\n",
      "8 'awaiting player n to discard' n ['7b', '6b', '6s', '9b', '9b'] ['3b']\n",
      "9 'player e must draw' e ['6b', '3s', '2b', '3s'] ['9b']\n",
      "10 'awaiting player e to discard' e ['6b', '3s', '2b', '3s', '5b'] ['9b']\n",
      "11 'player s must draw' s ['5b', '9s', '6s', '7s'] ['5b']\n",
      "12 'awaiting player s to discard' s ['5b', '9s', '6s', '7s', '8b'] ['5b']\n",
      "13 'player w must draw' w ['7s', '2b', '8b', '7s'] ['5b']\n",
      "14 'awaiting player w to discard' w ['7s', '2b', '8b', '7s', '5s'] ['5b']\n",
      "15 'player n must draw' n ['7b', '6b', '6s', '9b'] ['7s']\n",
      "16 'awaiting player n to discard' n ['7b', '6b', '6s', '9b', '2b'] ['7s']\n",
      "17 'player e must draw' e ['6b', '3s', '2b', '3s'] ['6b']\n",
      "18 'awaiting player e to discard' e ['6b', '3s', '2b', '3s', '4s'] ['6b']\n",
      "19 'player s must draw' s ['9s', '6s', '7s', '8b'] ['2b']\n",
      "20 'awaiting player s to discard' s ['9s', '6s', '7s', '8b', '2s'] ['2b']\n",
      "21 'player w must draw' w ['2b', '8b', '7s', '5s'] ['9s']\n",
      "22 'awaiting player w to discard' w ['2b', '8b', '7s', '5s', '6s'] ['9s']\n",
      "23 'player n must draw' n ['7b', '6s', '9b', '2b'] ['5s']\n",
      "24 'awaiting player n to discard' n ['7b', '6s', '9b', '2b', '5b'] ['5s']\n",
      "25 'player e must draw' e ['6b', '3s', '3s', '4s'] ['6s']\n",
      "26 'awaiting player e to discard' e ['6b', '3s', '3s', '4s', '9s'] ['6s']\n",
      "27 'player s must draw' s ['6s', '7s', '8b', '2s'] ['6b']\n",
      "28 'awaiting player s to discard' s ['6s', '7s', '8b', '2s', '5s'] ['6b']\n",
      "29 'player w must draw' w ['2b', '8b', '7s', '6s'] ['8b']\n",
      "30 'awaiting player w to discard' w ['2b', '8b', '7s', '6s', '7b'] ['8b']\n",
      "31 'player n must draw' n ['7b', '9b', '2b', '5b'] ['8b']\n",
      "32 'awaiting player n to discard' n ['7b', '9b', '2b', '5b', '9b'] ['8b']\n",
      "33 'player e must draw' e ['3s', '3s', '4s', '9s'] ['7b']\n",
      "34 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '1s'] ['7b']\n",
      "35 'player s must draw' s ['6s', '7s', '2s', '5s'] ['1s']\n",
      "36 'awaiting player s to discard' s ['6s', '7s', '2s', '5s', '1s'] ['1s']\n",
      "37 'player w must draw' w ['2b', '7s', '6s', '7b'] ['6s']\n",
      "38 'awaiting player w to discard' w ['2b', '7s', '6s', '7b', '4s'] ['6s']\n",
      "39 'player n must draw' n ['9b', '2b', '5b', '9b'] ['4s']\n",
      "40 'awaiting player n to discard' n ['9b', '2b', '5b', '9b', '3b'] ['4s']\n",
      "41 'player e must draw' e ['3s', '3s', '4s', '9s'] ['5b']\n",
      "42 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '1b'] ['5b']\n",
      "43 'player s must draw' s ['7s', '2s', '5s', '1s'] ['1b']\n",
      "44 'awaiting player s to discard' s ['7s', '2s', '5s', '1s', '3s'] ['1b']\n",
      "45 'player w must draw' w ['2b', '7s', '6s', '7b'] ['7s']\n",
      "46 'awaiting player w to discard' w ['2b', '7s', '6s', '7b', '4b'] ['7s']\n",
      "47 'player n must draw' n ['9b', '2b', '9b', '3b'] ['2b']\n",
      "48 'awaiting player n to discard' n ['9b', '2b', '9b', '3b', '7s'] ['2b']\n",
      "49 'player e must draw' e ['3s', '3s', '4s', '9s'] ['3b']\n",
      "50 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '5b'] ['3b']\n",
      "51 'player s must draw' s ['2s', '5s', '1s', '3s'] ['5b']\n",
      "52 'awaiting player s to discard' s ['2s', '5s', '1s', '3s', '8s'] ['5b']\n",
      "53 'awaiting player w to draw or pickup' w ['7s', '6s', '7b', '4b'] ['5s']\n",
      "54 'awaiting player w to discard' w ['7b', '4b'] ['5b']\n",
      "55 'player n must draw' n ['9b', '2b', '9b', '7s'] ['4b']\n",
      "56 'awaiting player n to discard' n ['9b', '2b', '9b', '7s', '3b'] ['4b']\n",
      "57 'player e must draw' e ['3s', '3s', '4s', '9s'] ['9b']\n",
      "58 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '4b'] ['9b']\n",
      "59 'player s must draw' s ['2s', '1s', '3s', '8s'] ['4b']\n",
      "60 'awaiting player s to discard' s ['2s', '1s', '3s', '8s', '6b'] ['4b']\n",
      "61 'player w must draw' w ['7b'] ['6b']\n",
      "62 'awaiting player w to discard' w ['7b', '4b'] ['6b']\n",
      "63 'player n must draw' n ['2b', '9b', '7s', '3b'] ['7b']\n",
      "64 'awaiting player n to discard' n ['2b', '9b', '7s', '3b', '6b'] ['7b']\n",
      "65 'player e must draw' e ['3s', '3s', '4s', '9s'] ['3b']\n",
      "66 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '1b'] ['3b']\n",
      "67 'player s must draw' s ['2s', '1s', '3s', '8s'] ['1b']\n",
      "68 'awaiting player s to discard' s ['2s', '1s', '3s', '8s', '4b'] ['1b']\n",
      "69 'player w must draw' w ['4b'] ['3s']\n",
      "70 'awaiting player w to discard' w ['4b', '2s'] ['3s']\n",
      "71 'player n must draw' n ['2b', '9b', '7s', '6b'] ['2s']\n",
      "72 'awaiting player n to discard' n ['2b', '9b', '7s', '6b', '8s'] ['2s']\n",
      "73 'player e must draw' e ['3s', '3s', '4s', '9s'] ['9b']\n",
      "74 'awaiting player e to discard' e ['3s', '3s', '4s', '9s', '5s'] ['9b']\n",
      "75 'player s must draw' s ['2s', '1s', '8s', '4b'] ['9s']\n",
      "76 'awaiting player s to discard' s ['2s', '1s', '8s', '4b', '8s'] ['9s']\n",
      "77 'player w must draw' w ['4b'] ['2s']\n",
      "78 'awaiting player w to discard' w ['4b', '8b'] ['2s']\n",
      "79 'player n must draw' n ['2b', '7s', '6b', '8s'] ['8b']\n",
      "80 'awaiting player n to discard' n ['2b', '7s', '6b', '8s', '3b'] ['8b']\n",
      "81 'player e must draw' e ['3s', '3s', '4s', '5s'] ['8s']\n",
      "82 'awaiting player e to discard' e ['3s', '3s', '4s', '5s', '1b'] ['8s']\n",
      "83 'player s must draw' s ['1s', '8s', '4b', '8s'] ['1b']\n",
      "84 'awaiting player s to discard' s ['1s', '8s', '4b', '8s', '1s'] ['1b']\n",
      "85 'player w must draw' w ['4b'] ['8s']\n",
      "86 'awaiting player w to discard' w ['4b', '2s'] ['8s']\n",
      "87 'player n must draw' n ['2b', '7s', '6b', '3b'] ['2s']\n",
      "88 'awaiting player n to discard' n ['2b', '7s', '6b', '3b', '9s'] ['2s']\n",
      "89 'player e must draw' e ['3s', '3s', '4s', '5s'] ['2b']\n",
      "90 'awaiting player e to discard' e ['3s', '3s', '4s', '5s', '7b'] ['2b']\n",
      "91 'player s must draw' s ['1s', '4b', '8s', '1s'] ['7b']\n",
      "92 'awaiting player s to discard' s ['1s', '4b', '8s', '1s', '1s'] ['7b']\n",
      "93 'awaiting player w to draw or pickup' w ['4b'] ['4b']\n",
      "94 'awaiting player w to discard' w ['4b', '4b'] ['7b']\n",
      "95 'player n must draw' n ['7s', '6b', '3b', '9s'] ['4b']\n",
      "96 'awaiting player n to discard' n ['7s', '6b', '3b', '9s', '8b'] ['4b']\n",
      "97 'player e must draw' e ['3s', '3s', '4s', '5s'] ['8b']\n",
      "98 'awaiting player e to discard' e ['3s', '3s', '4s', '5s', '8s'] ['8b']\n",
      "99 'player s must draw' s ['1s', '8s', '1s', '1s'] ['3s']\n",
      "100 'awaiting player s to discard' s ['1s', '8s', '1s', '1s', '4s'] ['3s']\n",
      "101 'player w must draw' w ['4b'] ['1s']\n",
      "102 'awaiting player w to discard' w ['4b', '7b'] ['1s']\n",
      "103 'player n must draw' n ['7s', '6b', '3b', '9s'] ['7b']\n",
      "104 'awaiting player n to discard' n ['7s', '6b', '3b', '9s', '6s'] ['7b']\n",
      "105 'player e must draw' e ['3s', '4s', '5s', '8s'] ['6b']\n",
      "106 'awaiting player e to discard' e ['3s', '4s', '5s', '8s', '4s'] ['6b']\n",
      "107 'player s must draw' s ['8s', '1s', '1s', '4s'] ['3s']\n",
      "108 'awaiting player s to discard' s ['8s', '1s', '1s', '4s', '9s'] ['3s']\n",
      "109 'player w must draw' w ['4b'] ['8s']\n",
      "110 'awaiting player w to discard' w ['4b', '3s'] ['8s']\n",
      "111 'player n must draw' n ['7s', '3b', '9s', '6s'] ['3s']\n",
      "112 'awaiting player n to discard' n ['7s', '3b', '9s', '6s', '2s'] ['3s']\n",
      "113 'player e must draw' e ['4s', '5s', '8s', '4s'] ['7s']\n",
      "114 e {'game_over': True, 'winning_player': 'draw', 'message': 'game is draw, no tiles left', 'turn': 'e'} e ['4s', '5s', '8s', '4s', '2b']\n"
     ]
    }
   ],
   "source": [
    "game_statistics = {'game_lengths_all': [], 'game_lengths_draws': []}\n",
    "multi_agent_game_manager(NetMahjongAgentInference(model),SimpleMahjongAgent(),game_statistics,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "68c0b8a4-1f83-4f80-8d96-43577c035d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_over': False,\n",
       " 'message': 'awaiting player n to discard',\n",
       " 'turn': 'n',\n",
       " 'await_action': 2}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrator(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01d5b7fa-520e-4ff9-a132-8947341ec412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deck': ['4b',\n",
       "  '3b',\n",
       "  '4s',\n",
       "  '5b',\n",
       "  '2b',\n",
       "  '8s',\n",
       "  '3s',\n",
       "  '4b',\n",
       "  '8b',\n",
       "  '7s',\n",
       "  '6b',\n",
       "  '4s',\n",
       "  '1s',\n",
       "  '3b',\n",
       "  '7s',\n",
       "  '4b',\n",
       "  '5s',\n",
       "  '1s',\n",
       "  '9b',\n",
       "  '3b',\n",
       "  '8b',\n",
       "  '5s',\n",
       "  '9s',\n",
       "  '3s',\n",
       "  '4b',\n",
       "  '2s',\n",
       "  '5b',\n",
       "  '6s',\n",
       "  '8b',\n",
       "  '8s',\n",
       "  '5b',\n",
       "  '4s',\n",
       "  '3s',\n",
       "  '9b',\n",
       "  '1b',\n",
       "  '8s',\n",
       "  '3b',\n",
       "  '1b',\n",
       "  '6s',\n",
       "  '6b',\n",
       "  '9s',\n",
       "  '2b',\n",
       "  '9b',\n",
       "  '7s',\n",
       "  '7b',\n",
       "  '2b',\n",
       "  '2s',\n",
       "  '1b',\n",
       "  '5s',\n",
       "  '2b',\n",
       "  '3s',\n",
       "  '2s',\n",
       "  '7b',\n",
       "  '6b',\n",
       "  '9b'],\n",
       " 'discard': ['1s'],\n",
       " 'n': ['9s', '5b', '4s', '8b'],\n",
       " 'e': ['1b', '6b', '6s', '1s'],\n",
       " 's': ['5s', '7s', '6s', '2s'],\n",
       " 'w': ['7b', '7b', '9s', '8s'],\n",
       " 'turn': 'e'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = action2(e1,'1s')\n",
    "e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a005de15-391a-4998-8a52-4dc0020f1df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_pickup(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea87171c-c88f-4b13-b0a0-897d4cd6c50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_over': True,\n",
       " 'winning_player': 'draw',\n",
       " 'message': 'game is draw, no tiles left',\n",
       " 'turn': 'n'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e0 = first_draw(deal(random_init(tiles_list)))\n",
    "e0['deck'] = []\n",
    "narrator(e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700183c-c5c9-4ba2-bad6-9ae0ebdf4db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
